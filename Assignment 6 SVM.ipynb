{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mounted-douglas",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "## Assignment Instructions\n",
    "Repo: https://github.com/cesar-ca/cs156-assign6\n",
    "\n",
    "### Machine Learning Fashionista 2.0\n",
    "\n",
    "In this assignment we revisit the dataset from the **dimension reduction unit**. The pictures of clothing are all originally taken from **ImageNet**, which is a large dataset containing over a million photos with many different categories. Every year there is a competition to see which techniques perform the best. The winning entry is then open-sourced and made available to all machine learning researchers for further research or to allow the development of novel applications.\n",
    "\n",
    "**Support Vector Machines**\n",
    "\n",
    "- Train a support vector classifier using each of the following kernels:\n",
    "    - Linear\n",
    "    - Poly (degree = 2)\n",
    "    - RBF\n",
    "- If you encounter any issues with training time or memory issues, then you may use a reduced dataset, but carefully detail why and how you reduced the dataset. \n",
    "- Unnecessarily reducing the dataset will result in reduced grades!\n",
    "Report your error rates on the testing dataset for the different kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faced-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install python-resize-image\n",
    "#!pip3 install resizeimage\n",
    "#!pip3 install sklearn\n",
    "#!pip3 install skimage\n",
    "#!pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sonic-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for handling image data\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from glob import glob\n",
    "\n",
    "# More relevant libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle, seed, random, sample\n",
    "from collections import defaultdict\n",
    "\n",
    "# Importing statistical packages\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electronic-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages from machine learning models of sklearn\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complete-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "limited-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.io import imread_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sticky-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loading photos to a folder, doing pre-processing\n",
    "man_folder = '/Users/dmstudent1/Projects/Assignment6/man/*.JPEG'\n",
    "man_sample = '/Users/dmstudent1/Projects/Assignment6/man_sample/*.JPEG'\n",
    "man_files = glob('/Users/dmstudent1/Projects/Assignment6/man/*')\n",
    "\n",
    "woman_folder = '/Users/dmstudent1/Projects/Assignment6/woman/*.JPEG'\n",
    "woman_sample = '/Users/dmstudent1/Projects/Assignment6/woman_sample/*.JPEG'\n",
    "woman_files = glob('/Users/dmstudent1/Projects/Assignment6/woman/*')\n",
    "\n",
    "# Taking the photos in the folder together\n",
    "man_clothes = imread_collection(man_folder)\n",
    "man_sample_clothes = imread_collection(man_sample)\n",
    "\n",
    "woman_clothes = imread_collection(woman_folder)\n",
    "woman_sample_clothes = imread_collection(woman_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dynamic-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing the photos to work with the same dimensions throughout the data\n",
    "height_resize = 160\n",
    "width_resize = 120\n",
    "    \n",
    "# Resizing all male photos in the data\n",
    "man_resize = [resize(man_clothes[i], (height_resize, width_resize),\n",
    "                     mode='constant', anti_aliasing=True,\n",
    "                     anti_aliasing_sigma=None) for i in range(len(man_clothes))]\n",
    "\n",
    "man_sample_resize = [resize(man_sample_clothes[i], (height_resize, width_resize),\n",
    "                           mode='constant', anti_aliasing=True,\n",
    "                           anti_aliasing_sigma=None) for i in range(len(man_sample_clothes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comic-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:793: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "# Resizing all female clothing photos in the data \n",
    "woman_resize = [resize(woman_clothes[i], (height_resize, width_resize), \n",
    "                       mode='constant', anti_aliasing=True,\n",
    "                       anti_aliasing_sigma=None) for i in range(len(woman_clothes))]\n",
    "\n",
    "woman_sample_resize = [resize(woman_sample_clothes[i], (height_resize, width_resize),\n",
    "                             mode='constant', anti_aliasing=True,\n",
    "                             anti_aliasing_sigma=None) for i in range(len(woman_sample_clothes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amazing-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with the simple linear classifiers, the image data has to be stored as arrays\n",
    "man_array = np.array([i.flatten() for i in man_resize])\n",
    "woman_array = np.array([i.flatten() for i in woman_resize])\n",
    "\n",
    "# Consolidating the data in a single place with 1, 0 to determine if it is male or female clothing\n",
    "raw_data = [(row, '1') for row in man_array] + [(row, '0') for row in woman_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "human-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training set and test set\n",
    "X = np.array([x for (x,y) in raw_data])\n",
    "y = np.array([y for (x,y) in raw_data])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-machinery",
   "metadata": {},
   "source": [
    "**Support Vector Machines | Linear Kernel**\n",
    "\n",
    "Using the Fashionista dataset, we can train a support vector classifier using a Linear kernel\n",
    "\n",
    "Then, we report the error rate on the testing dataset for the linear kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "practical-constitutional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linear = svm.SVC(kernel='linear')\n",
    "clf_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vital-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"train score: \", clf_linear.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adopted-elements",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1018\n",
      "           1       1.00      1.00      1.00       991\n",
      "\n",
      "    accuracy                           1.00      2009\n",
      "   macro avg       1.00      1.00      1.00      2009\n",
      "weighted avg       1.00      1.00      1.00      2009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, clf_linear.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-shaft",
   "metadata": {},
   "source": [
    "**Support Vector Machines | Linear Kernel (With Sample)**\n",
    "\n",
    "Using the Fashionista dataset, we can train a support vector classifier using a Linear kernel\n",
    "\n",
    "Then, we report the error rate on the testing dataset for the linear kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "increased-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with the simple linear classifiers, the image data has to be stored as arrays\n",
    "man_array_sample = np.array([i.flatten() for i in man_sample_resize])\n",
    "woman_array_sample = np.array([i.flatten() for i in woman_sample_resize])\n",
    "\n",
    "# Consolidating the data in a single place with 1, 0 to determine if it is male or female clothing\n",
    "raw_data_sample = [(row, '1') for row in man_array_sample] + [(row, '0') for row in woman_array_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afraid-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training set and test set\n",
    "X_sample = np.array([x for (x,y) in raw_data_sample])\n",
    "y_sample = np.array([y for (x,y) in raw_data_sample])\n",
    "\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sample, y_sample, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stupid-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sample = svm.SVC(kernel='linear')\n",
    "clf_sample.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "renewable-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"train score: \", clf_sample.score(X_train_sample, y_train_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excellent-baptist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       698\n",
      "           1       1.00      1.00      1.00       710\n",
      "\n",
      "    accuracy                           1.00      1408\n",
      "   macro avg       1.00      1.00      1.00      1408\n",
      "weighted avg       1.00      1.00      1.00      1408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train_sample, clf_sample.predict(X_train_sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-regular",
   "metadata": {},
   "source": [
    "**Support Vector Machines | Poly (degree = 2) Kernel**\n",
    "\n",
    "Using the Fashionista dataset, we can train a support vector classifier using a Poly (degree = 2) kernel\n",
    "\n",
    "Then, we report the error rate on the testing dataset for the Poly (degree = 2) kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unnecessary-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=2, kernel='poly')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_poly = svm.SVC(kernel='poly',degree=2)\n",
    "clf_poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "irish-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9342956694873071\n"
     ]
    }
   ],
   "source": [
    "print(\"train score: \", clf_poly.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "defensive-engagement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      1018\n",
      "           1       0.92      0.95      0.93       991\n",
      "\n",
      "    accuracy                           0.93      2009\n",
      "   macro avg       0.93      0.93      0.93      2009\n",
      "weighted avg       0.93      0.93      0.93      2009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, clf_poly.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-aberdeen",
   "metadata": {},
   "source": [
    "**Support Vector Machines | RBF Kernel**\n",
    "\n",
    "Using the Fashionista dataset, we can train a support vector classifier using a RBF kernel\n",
    "\n",
    "Then, we report the error rate on the testing dataset for the RBF kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "classical-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rbf = svm.SVC(kernel='rbf')\n",
    "clf_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "impossible-staff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8680935788949726\n"
     ]
    }
   ],
   "source": [
    "print(\"train score: \", clf_rbf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "professional-graduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1018\n",
      "           1       0.87      0.86      0.87       991\n",
      "\n",
      "    accuracy                           0.87      2009\n",
      "   macro avg       0.87      0.87      0.87      2009\n",
      "weighted avg       0.87      0.87      0.87      2009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, clf_rbf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-democracy",
   "metadata": {},
   "source": [
    "Using Support Vector Machine for image classification for the fashionista dataset with female and male clothing proved to be helpful with high precision and recall across different kernels.\n",
    "\n",
    "Using a linear kernel, there was an issue with training as it was overfitting by getting 100% rates so I used a linear kernel on a reduced (sampled) dataset to provide another look at the linear kernel.\n",
    "\n",
    "Using a reduced data set for the linear kernel, we see better results with high precision and recall.\n",
    "\n",
    "For the poly (degree = 2) kernel, we also see very good results with high precision and recall values.\n",
    "\n",
    "The RBF kernel underperformed compared to the other kernel with lower values of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "spare-fisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "div.cell { /* Tunes the space between cells */\n",
       "margin-top:1em;\n",
       "margin-bottom:1em;\n",
       "}\n",
       "\n",
       "div.texxt_cell_render h1 { /* Main titles bigger, centered */\n",
       "font-size: 2.2em;\n",
       "line-height:1.4em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { /* Parts names nearer from the text */\n",
       "margin-bottom: -0.4em;\n",
       "}\n",
       "\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Times New Roman';\n",
       "font-size:1.2em;\n",
       "line-height:1.4em;\n",
       "padding-left:2em;\n",
       "padding-right:2em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.cell { /* Tunes the space between cells */\n",
    "margin-top:1em;\n",
    "margin-bottom:1em;\n",
    "}\n",
    "\n",
    "div.texxt_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 2.2em;\n",
    "line-height:1.4em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { /* Parts names nearer from the text */\n",
    "margin-bottom: -0.4em;\n",
    "}\n",
    "\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.2em;\n",
    "line-height:1.4em;\n",
    "padding-left:2em;\n",
    "padding-right:2em;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
